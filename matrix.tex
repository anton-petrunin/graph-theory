\chapter{Matrix theorem}


\section{Adjacency matrix}

Let us describe a way to encode a given multigraph $G$ with $p$ vertices by an $p{\times}p$ matrix.
First, enumerate the vertices of the multigraph by numbers from $1$ to $p$;
such a multigraph will be called \index{labeled graph}\emph{labeled}. 
Consider the matrix $A=A_G$ with the component $a_{i,j}$ equal to the number of edges from the $i$-th vertex to the $j$-th vertex of $G$.

This matrix $A$ is called the \index{adjacency matrix}\emph{adjacency matrix} of $G$.
Note that $A$ is \index{symmetric matrix}\emph{symmetric}; that is, $a_{i,j}=a_{j,i}$ for any pair $i,j$.
Also, the diagonal components of $A$ vanish; that is, $a_{i,i}=0$ for any $i$.

{

\begin{wrapfigure}{o}{28 mm}
\begin{tikzpicture}[scale=1.4,
  thick,main node/.style={circle,draw,font=\sffamily\bfseries,minimum size=3mm}]

  \node[main node] (1) at (0,15/6) {$1$};
  \node[main node] (2) at (1,15/6){$2$};
  \node[main node] (11) at (1.5,10/6){$3$};
  \node[main node] (12) at (.5,10/6) {$4$};

  \path[every node/.style={font=\sffamily\small}]
  
   (1) edge node{}(2)
   (1) edge node{}(12)
   (2) edge[bend left] node{}(12)
   (2) edge[bend right] node{}(12)
   (2) edge node{}(11);
\end{tikzpicture}
\end{wrapfigure}


For example, for the labeled multigraph $G$ shown on the diagram, we get the following adjacency matrix:
\[A=\left(
\begin{matrix}
0&1&0&1
\\
1&0&1&2
\\
0&1&0&0
\\
1&2&0&0
\end{matrix}
\right).\]

}

\begin{thm}{Exercise}\label{ex:n(walks)}
Let $A$ be the adjacency matrix of a labeled multigraph.
Show that the components $b_{i,j}$ of the $n$-th power $A^n$ is the number of walks of length $n$ in the graph from vertex $i$ to vertex $j$. 
\end{thm}

\section{Kirchhoff minor}

In this section, we construct a special matrix called the \textit{Kirchhoff minor}, associated with a pseudograph,
and discuss its basic properties.
This matrix will be used in the next section in a formula for the number of spanning trees in a pseudograph~$G$.
Since loops do not change the number of spanning trees, we can remove all of them.
In other words, we can (and will) always assume that $G$ is a multigraph. 

Fix a multigraph $G$ and consider its adjacency matrix $A=A_G$;
it is a $p{\times}p$ symmetric matrix with zeros on the diagonal.

\begin{enumerate}
\item Revert the signs of the components of $A$ and exchange the zeros on the diagonal for the degrees of the corresponding vertices. 
The obtained matrix $A'$ is called the \index{Kirchhoff matrix}\emph{Kirchhoff matrix}, {}\emph{Laplacian matrix} or {}\emph{admittance matrix} of the graph $G$.

\item Delete from $A'$ the last column and the last row;
the obtained matrix $M=M_G$ will be called the \index{Kirchhoff minor}\emph{Kirchhoff minor} of the labeled pseudograph $G$.
\end{enumerate}

{

\begin{wrapfigure}{r}{28 mm}
\vskip-4mm
\begin{tikzpicture}[scale=1.4,
  thick,main node/.style={circle,draw,font=\sffamily\bfseries,minimum size=3mm}]

  \node[main node] (1) at (0,15/6) {$1$};
  \node[main node] (2) at (1,15/6){$2$};
  \node[main node] (11) at (1.5,10/6){$3$};
  \node[main node] (12) at (.5,10/6) {$4$};

  \path[every node/.style={font=\sffamily\small}]
  
   (1) edge node{}(2)
   (1) edge node{}(12)
   (2) edge[bend left] node{}(12)
   (2) edge[bend right] node{}(12)
   (2) edge node{}(11);
\end{tikzpicture}
\end{wrapfigure}

For example, the labeled multigraph $G$ on the diagram has the following Kirchhoff matrix and Kirchhoff minor:
\[A'=\left(
\begin{matrix}
2&-1&0&-1
\\
-1&4&-1&-2
\\
0&-1&1&0
\\
-1&-2&0&3
\end{matrix}
\right),
\quad 
M=\left(
\begin{matrix}
2&-1&0
\\
-1&4&-1
\\
0&-1&1
\end{matrix}
\right).\]

}

\begin{thm}{Exercise}\label{ex:Kirchhoff-row}
Show that in any Kirchhoff matrix $A'$ the sum of the components in each row or column vanishes.
Conclude that 
\[\det A'=0.\]

\end{thm}

\begin{thm}{Exercise}\label{ex:minor>graph}
Draw a labeled pseudograph with the following Kirchhoff minor:
\[\left(
\begin{matrix}
4&-1&-1&-1&0
\\
-1&4&-1&0&-1
\\
-1&-1&4&-1&-1
\\
-1&0&-1&4&-1
\\
0&-1&-1&-1&4
\end{matrix}
\right).\]
\end{thm}

\begin{thm}{Exercise}\label{ex:sum-kirchhoff}
Show that the sum of all components in every column of the Kirchhoff minor is nonnegative.

Moreover, the sum of all components in the $i$-th column vanishes if and only if the $i$-th vertex is not adjacent to the last vertex.
\end{thm}



\parbf{Relabeling.}
Let us understand what happens with Kirchhoff minor and its determinant as we swap two labels distinct from the last one.

\begin{wrapfigure}[6]{o}{28 mm}
\begin{tikzpicture}[scale=1.4,
  thick,main node/.style={circle,draw,font=\sffamily\bfseries,minimum size=3mm}]

  \node[main node] (1) at (0,15/6) {$1$};
  \node[main node] (2) at (1,15/6){$3$};
  \node[main node] (11) at (1.5,10/6){$2$};
  \node[main node] (12) at (.5,10/6) {$4$};

  \path[every node/.style={font=\sffamily\small}]
  
   
   (1) edge node{}(2)
   (1) edge node{}(12)
   (2) edge[bend left] node{}(12)
   (2) edge[bend right] node{}(12)
   (2) edge node{}(11);
\end{tikzpicture}
\end{wrapfigure}

For example, if we swap the labels $2$ and $3$ in the graph above,
we get another labeling shown on the diagram.
Then the corresponding Kirchhoff minor will be 
\[
M'=\left(
\begin{matrix}
2&0&-1
\\
0&1&-1
\\
-1&-1&4
\end{matrix}
\right),
\]
which is obtained from $M$ by swapping columns $2$ and $3$ followed by swapping rows $2$ and $3$.

Note that swapping a pair of columns or rows changes the sign of the determinant.
Therefore, swapping one pair of rows and one pair of columns does not change the determinant.
Summarizing we get the following:

\begin{thm}{Observation}\label{observaiton:swap}
Assume $G$ is a labeled graph with $p$ vertices, and $M_G$ is its Kirchhoff minor.
If we swap two labels $i,j<p$, then the corresponding Kirchhoff minor $M'_G$ can be obtained from $M_G$ by swapping columns $i$ and $j$ and then swapping rows $i$ and $j$.
In particular, 
\[\det M'_G=\det M_G.\]

\end{thm}

\parbf{Deletion and contraction.}
Let us understand what happens with the Kirchhoff minor if we delete or contract an edge in the labeled multigraph.
(If after the contraction of an edge we get loops, we remove it; this way we obtain a multigraph.)

Assume an edge $e$ connects the first and the last vertex of a labeled multigraph $G$ as shown in the following example:
\begin{center}
\begin{tikzpicture}[scale=1.4,
  thick,main node/.style={circle,draw,font=\sffamily\bfseries,minimum size=3mm}]

  \node[main node] (1) at (0,15/6) {$1$};
  \node[main node] (2) at (1,15/6){$2$};
  \node[main node] (11) at (1.5,10/6){$3$};
  \node[main node] (12) at (.5,10/6) {$4$};

  \path[every node/.style={font=\sffamily\small}]
  
   (1) edge node{}(2)
   (12) edge node[auto]{$e$}(1)
   (2) edge[bend left] node{}(12)
   (2) edge[bend right] node{}(12)
   (2) edge node{}(11);
\node[align=center, yshift=2em] (title) 
    at (current bounding box.north)
    {$G$};
\end{tikzpicture}
\hskip5mm
\begin{tikzpicture}[scale=1.4,
  thick,main node/.style={circle,draw,font=\sffamily\bfseries,minimum size=3mm}]

  \node[main node] (1) at (0,15/6) {$1$};
  \node[main node] (2) at (1,15/6){$2$};
  \node[main node] (11) at (1.5,10/6){$3$};
  \node[main node] (12) at (.5,10/6) {$4$};

  \path[every node/.style={font=\sffamily\small}]
  
   (1) edge node{}(2)
   (2) edge[bend left] node{}(12)
   (2) edge[bend right] node{}(12)
   (2) edge node{}(11);
\node[align=center, yshift=2em] (title) 
    at (current bounding box.north)
    {$G-e$};
\end{tikzpicture}
\hskip10mm
\begin{tikzpicture}[scale=1.4,
  thick,main node/.style={circle,draw,font=\sffamily\bfseries,minimum size=3mm}]

  \node[main node] (2) at (1,15/6){$2$};
  \node[main node] (11) at (1.5,10/6){$3$};
  \node[main node] (12) at (.5,10/6) {$4$};

  \path[every node/.style={font=\sffamily\small}]
  
  (2) edge node{}(12)
   (2) edge[bend left] node{}(12)
   (2) edge[bend right] node{}(12)
   (2) edge node{}(11);
   \node[align=center, yshift=2em] (title) 
    at (current bounding box.north)
    {$G/e$};
\end{tikzpicture}
\end{center}

Note that deleting $e$ only reduces the corner component of $M_G$ by one,
while contracting it removes the first row and column.
That is, since 
\[M_G=
\left(
\begin{matrix}
2&-1&0
\\
-1&4&-1
\\
0&-1&1
\end{matrix}
\right),\]
we have
\[M_{G- e}=\left(
\begin{matrix}
1&-1&0
\\
-1&4&-1
\\
0&-1&1
\end{matrix}
\right)
\quad\text{and}\quad
M_{G/e}=\left(
\begin{matrix}
4&-1
\\
-1&1
\end{matrix}
\right).\]

Summarizing the above discussion, we get the following:

\begin{thm}{Observation}\label{observaiton:dpc}
Assume $e$ is an edge of a labeled multigraph $G$ between the first and last vertices and $M_G$ is the Kirchhoff minor of~$G$.
Then 
\begin{enumerate}[(a)]
\item the Kirchhoff minor  $M_{G- e}$ of $G- e$ can be obtained from  $M_G$ by subtracting 1 from the corner element with index (1,1);
\item the Kirchhoff minor $M_{G/e}$ of $G/e$ can be obtained  from  $M_G$ by removing the first row and the first column in $M_G$.
\end{enumerate}

In particular, applying the cofactor expansion of a determinant, we get that
\[\det M_G=\det M_{G- e}+\det M_{G/ e}.\]

\end{thm}

Note that the last formula resembles the deletion-plus-contraction formula.
This observation will be a key to the proof of the matrix theorem; see next section.

\section{Matrix theorem}


\begin{thm}{Matrix theorem}\label{thm:matrix}
Let $M$ be the Kirchhoff minor of a labeled multigraph $G$ with at least two vertices.
Then
\[s(G)=\det M,\eqlbl{eq:matrix-formula}\]
where $s(G)$ denotes the number of spanning trees in $G$.
\end{thm}


\parit{Proof.}
Denote by $d$ the degree of the last vertex in $G$.

Assume $d=0$.
Then $G$ is not connected and therefore $s(G)=0$.
On the other hand, the sum in each row of $M_G$ vanishes (compare to Exercise~\ref{ex:sum-kirchhoff}).
Hence the sum of all columns in $M_G$ vanish;
in particular, the columns in $M_G$ are linearly dependent and hence $\det M_G=0$.
Hence the equality \ref{eq:matrix-formula} holds if $d=0$.

As usual, we denote by $p$ and $q$ the number of vertices and edges in $G$; by the assumption we have that $p\ge 2$.

\begin{wrapfigure}{o}{25 mm}
\vskip0mm
\centering
\includegraphics{mppics/pic-41}
\end{wrapfigure}

Assume $p=2$; that is, $G$ has two vertices and $q$ parallel edges connecting them.
Clearly, $s(G)=q$.
Further note that $M_G=(q)$; that is,  the Kirchhoff minor $M_G$ is a $1{\times}1$ matrix with a single component $q$.
In particular, $\det M_G=q$ and therefore the equality \ref{eq:matrix-formula} holds.

Assume the equality \ref{eq:matrix-formula} does not hold in general;
choose a \index{minimal criminal}\emph{minimal criminal} graph $G$;
that is, a graph that minimize the value $p+q$ among the graphs violating \ref{eq:matrix-formula}.

From above we have that $p>2$ and $d>0$.
Note that we may assume that the first and last vertices of $G$ are adjacent;
otherwise permute pair of labels $1$ and some $j<p$  and apply Observation~\ref{observaiton:swap}.
Denote by $e$ the edge between the first and last vertex.

Note that the total number of vertices and edges in the pseudographs $G- e$ and $G/e$ are smaller than $p+q$.
Therefore, we have that
\begin{align*}
s(G- e)&=\det M_{G- e},
&
s(G/e)&=\det M_{G/e}.
\end{align*}
Applying these two identities together with the deletion-plus-contraction formula 
and Observation~\ref{observaiton:dpc}, we get that
\begin{align*}
s(G)&=s(G- e)+s(G/e)=
\\
&=\det M_{G- e}+\det M_{G/e}=
\\
&=\det M_G;
\end{align*}
that is, the identity \ref{eq:matrix-formula} holds for $G$ --- a contradiction.
\qeds


\begin{thm}{Exercise}\label{ex:K33W6Q3}
Fix a labeling for each of the following graphs, 
find its Kirchhoff minor and use the matrix theorem to find the number of spanning trees.
\begin{enumerate}[(a)]
\item $s(K_{3,3})$;
\item $s(W_6)$;
\item $s(Q_3)$.
\end{enumerate}
(Use \href{https://matrix.reshish.com/determinant.php}{\texttt{https://matrix.reshish.com/determinant.php}}, or any other matrix calculator.)
\end{thm}


\section{Calculation of determinants}

In this section, we recall key properties of the determinant which will be used in the next section.

Let $M$ be an $n{\times}n$-matrix; that is, a table $n{\times}n$, filled with numbers called {}\emph{components} of the matrix.
The determinant $\det M$ is a polynomial of the $n^2$ components of $M$, satisfying the following conditions:
\begin{enumerate}
 \item\label{1} The unit matrix has determinant 1; that is,
\[
\det\left(
\begin{matrix}
1&0&\cdots&0
\\
0&1&\ddots&\vdots
\\
\vdots&\ddots&\ddots&0
\\
0&\cdots&0&1
\end{matrix}
\right)=1.
\]
\item\label{2} If we multiply each component of one of the rows of  by a number~$\lambda$, then for the obtained matrix $M'$, we have
\[\det M'=\lambda\cdot \det M.\]

\item\label{3} If one adds (or subtracts) term-by-term components
in one row to another row, then the obtained matrix $M'$ has the same determinant; that is
\[\det M'= \det M.\]
\end{enumerate}
These three conditions define the determinant in a uniquely. 
We will not give a proof of the statement; it is not evident and not complicated (sooner or later you will have to learn it if it is not done already).

\begin{thm}{Exercise}\label{ex:det}
Show that the following property follows from the properties above.
\end{thm}

\begin{enumerate}[resume]
 \item Interchanging any pair of rows of a matrix multiplies its determinant by $-1$; that is, if a matrix $M'$ is obtained from a matrix $M$ by permuting two of its rows, then 
\[\det M'=-\det M.\]
\end{enumerate}

The determinant of $n\times n$-matrix can be written explicitly as a sum of $n!$ terms. 
For example, 
\[
a_1{\cdot} b_2{\cdot} c_3+a_2{\cdot} b_3{\cdot} c_1+a_3{\cdot} b_1{\cdot} c_2-a_3{\cdot} b_2{\cdot} c_1-a_2{\cdot} b_1{\cdot} c_3-a_1{\cdot} b_3{\cdot} c_2\]
is the determinant of the matrix
\[M=\left(
\begin{matrix}
a_1&b_1&c_1
\\
a_2&b_2&c_2
\\
a_3&b_3&c_3
\end{matrix}
\right).\]
However, the properties described above give a more convenient and faster way to calculate the determinant, especially for larger~$n$.

Let us show it in one example which will be needed in the next section.
\begin{align*}
\det\left(
\begin{matrix}
4&-1&-1&-1
\\
-1&4&-1&-1
\\
-1&-1&4&-1
\\
-1&-1&-1&4
\end{matrix}
\right)
=
&\det\left(
\begin{matrix}
1&1&1&1
\\
-1&4&-1&-1
\\
-1&-1&4&-1
\\
-1&-1&-1&4
\end{matrix}
\right) 
=
\\
=
&\det\left(
\begin{matrix}
1&1&1&1
\\
0&5&0&0
\\
0&0&5&0
\\
0&0&0&5
\end{matrix}
\right)
=
\\
=
5^3\cdot
&\det\left(
\begin{matrix}
1&1&1&1
\\
0&1&0&0
\\
0&0&1&0
\\
0&0&0&1
\end{matrix}
\right)=
\\
=
5^3\cdot&\det\left(
\begin{matrix}
1&0&0&0
\\
0&1&0&0
\\
0&0&1&0
\\
0&0&0&1
\end{matrix}
\right)=
\\
=5^3&.
\end{align*}
Let us describe what we used on each line above:
\begin{enumerate}
\item property \ref{3} three times --- we add to the first row each of the remaining rows;
\item property \ref{3} three times --- we add the first row to each of the remaining three rows;
\item property \ref{2} three times;
\item property \ref{3} three times --- we subtract from the first row the remaining three rows;
\item property \ref{1}.
\end{enumerate}


\section{Cayley formula}

Recall that a \index{complete graph}\emph{complete graph} is a graph where each pair of vertices is connected by an edge;
a complete graph with $p$ vertices is denoted by~$K_p$.

Note that every vertex of $K_p$ has degree $p-1$.
Therefore, the Kirchhoff minor $M=M_{K_p}$ in the matrix formula \ref{eq:matrix-formula} for $K_p$ is the following $(p-1)\times (p-1)$-matrix:

\[
M=\left(
\begin{matrix}
p{-}1&-1&\cdots&-1
\\
-1&p{-}1&\ddots&\vdots
\\
\vdots&\ddots&\ddots&-1
\\
-1&\cdots&-1&p{-}1
\end{matrix}
\right).
\]

Following the steps at the end of the previous section, we get
\begin{align*}
\det\left(
\begin{matrix}
p{-}1&-1&\cdots&-1
\\
-1&p{-}1&\ddots&\vdots
\\
\vdots&\ddots&\ddots&-1
\\
-1&\cdots&-1&p{-}1
\end{matrix}
\right)
&=\det\left(
\begin{matrix}
1&1&\cdots&1
\\
-1&p{-}1&\ddots&\vdots
\\
\vdots&\ddots&\ddots&-1
\\
-1&\cdots&-1&p{-}1
\end{matrix}
\right)
=
\\
&=
\det\left(
\begin{matrix}
1&1&\cdots&1
\\
0&p&\ddots&\vdots
\\
\vdots&\ddots&\ddots&0
\\
0&\cdots&0&p
\end{matrix}
\right)=
\\
&=  p^{p-2}.
\end{align*}
That is,
\[\det M=p^{\,p-2}.\]
Therefore, applying the matrix theorem, we get the following:

\begin{thm}{Cayley formula}\label{thm:cayley}
 \[s(K_p)=p^{p-2};\]
that is, the number of spanning trees in the complete graph $K_p$ is $p^{p-2}$.
\end{thm}

\begin{thm}{Exercise}\label{ex:s(Kp-e)}
Show $s(K_p-e)=(p-2)\cdot p^{n-3}$ for any edge $e$ in~$K_p$. 
\end{thm}

\begin{thm}{Exercise}\label{ex:s(Kmn)}
Use the matrix theorem to show that 
\[s(K_{m,n})=m^{n-1}\cdot n^{m-1}.\]
\end{thm}



\section{Remarks}

There is a strong connection between counting spanning trees of a given graph,
calculations of currents in an electric chain 
and random walks; a good survey is given in the book by Peter Doyle and Laurie Snell \cite{doyle-snell}.
Let us give some examples.

Assume that the graph $G$ describes an electric chain;
each edge has resistance one Ohm,  and a battery is connected to the vertices $a$ and $b$.
Assume that the total current between these vertices is one Ampere.
The following procedure calculates the current $I_e$ along a given edge $e$.

Fix a direction of $e$.
Note that any spanning tree $T$ of $G$ has exactly one the following three properties:
(1) the edge $e$ appears on the (necessarily unique) path from $a$ to $b$ in $T$ with a positive orientation,
(2) the edge $e$ appears on the path from $a$ to $b$ in $T$ with a negative orientation,
(3) the edge $e$ does not appear on the path from $a$ to $b$ in $T$.
Denote by $s_+$, $s_-$, and $s_0$ the number of the trees in each group.
Clearly,
\[s(G)=s_++s_-+s_0.\]
Then  the current $I_e$ can be calculated using the following formula:
\[I_e=\frac{s_+-s_-}{s(G)}\cdot I.\]
This statement can be proved by checking Kirchhoff's rules for the currents calculated by this formula.

There are many other applications of Kirchhoff's rules to graph theory.
For example, they can be used to prove the Euler's formula
\[p-q+r=2,\]
where $p$, $q$, and $r$ denote the number of vertices, edges, and regions in a plane drawing of graphs \cite{levi}.



